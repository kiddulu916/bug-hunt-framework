"""
Vulnerability Analyzer Service
Analyzes, correlates, and deduplicates vulnerability findings from multiple scanners
"""

import logging
import hashlib
import re
from typing import Dict, List, Any, Set, Tuple
from collections import defaultdict
from dataclasses import dataclass
import difflib

from services.vulnerability_scanner import VulnerabilityFinding, VulnSeverity


@dataclass
class CorrelationRule:
    """Rule for correlating related vulnerabilities"""
    name: str
    vulnerability_types: List[str]
    url_similarity_threshold: float
    parameter_similarity_threshold: float
    evidence_correlation_func: callable
    severity_escalation_rule: callable


class VulnerabilityAnalyzer:
    """Service for analyzing and correlating vulnerability findings"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # Initialize correlation rules
        self.correlation_rules = self._initialize_correlation_rules()
        
        # False positive patterns
        self.false_positive_patterns = self._initialize_false_positive_patterns()
        
        # Severity escalation rules
        self.severity_escalation_rules = self._initialize_severity_rules()
    
    async def analyze_findings(self, raw_findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Analyze and process vulnerability findings"""
        
        if not raw_findings:
            return []
        
        self.logger.info(f"Analyzing {len(raw_findings)} raw vulnerability findings")
        
        # Step 1: Filter out false positives
        filtered_findings = await self._filter_false_positives(raw_findings)
        self.logger.info(f"After false positive filtering: {len(filtered_findings)} findings")
        
        # Step 2: Deduplicate similar findings
        deduplicated_findings = await self._deduplicate_findings(filtered_findings)
        self.logger.info(f"After deduplication: {len(deduplicated_findings)} findings")
        
        # Step 3: Correlate related vulnerabilities
        correlated_findings = await self._correlate_vulnerabilities(deduplicated_findings)
        self.logger.info(f"After correlation: {len(correlated_findings)} findings")
        
        # Step 4: Apply severity escalation rules
        escalated_findings = await self._apply_severity_escalation(correlated_findings)
        self.logger.info(f"After severity escalation: {len(escalated_findings)} findings")
        
        # Step 5: Enrich findings with additional context
        enriched_findings = await self._enrich_findings(escalated_findings)
        self.logger.info(f"Analysis complete: {len(enriched_findings)} final findings")
        
        return enriched_findings
    
    async def _filter_false_positives(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Filter out likely false positive findings"""
        filtered = []
        
        for finding in findings:
            is_false_positive = False
            
            # Check against false positive patterns
            for pattern_info in self.false_positive_patterns:
                if self._matches_false_positive_pattern(finding, pattern_info):
                    is_false_positive = True
                    self.logger.debug(f"Filtered false positive: {finding.name} - {pattern_info['reason']}")
                    break
            
            if not is_false_positive:
                filtered.append(finding)
        
        return filtered
    
    async def _deduplicate_findings(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Remove duplicate vulnerability findings"""
        
        if len(findings) <= 1:
            return findings
        
        # Group findings by similarity
        similarity_groups = []
        processed = set()
        
        for i, finding in enumerate(findings):
            if i in processed:
                continue
            
            # Create new group with this finding
            group = [finding]
            processed.add(i)
            
            # Find similar findings
            for j, other_finding in enumerate(findings[i+1:], i+1):
                if j in processed:
                    continue
                
                similarity = self._calculate_finding_similarity(finding, other_finding)
                
                if similarity > 0.8:  # High similarity threshold
                    group.append(other_finding)
                    processed.add(j)
            
            similarity_groups.append(group)
        
        # Merge similar findings
        deduplicated = []
        for group in similarity_groups:
            if len(group) == 1:
                deduplicated.append(group[0])
            else:
                merged_finding = self._merge_similar_findings(group)
                deduplicated.append(merged_finding)
        
        return deduplicated
    
    async def _correlate_vulnerabilities(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Correlate related vulnerabilities and create correlation metadata"""
        
        # Apply correlation rules
        for rule in self.correlation_rules:
            findings = await self._apply_correlation_rule(findings, rule)
        
        return findings
    
    async def _apply_severity_escalation(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Apply severity escalation rules based on finding combinations"""
        
        # Group findings by target URL base
        url_groups = defaultdict(list)
        for finding in findings:
            base_url = self._get_base_url(finding.affected_url)
            url_groups[base_url].append(finding)
        
        escalated_findings = []
        
        for base_url, url_findings in url_groups.items():
            # Apply escalation rules
            escalated_group = self._apply_escalation_rules_to_group(url_findings)
            escalated_findings.extend(escalated_group)
        
        return escalated_findings
    
    async def _enrich_findings(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Enrich findings with additional context and metadata"""
        
        enriched = []
        
        for finding in findings:
            # Add CVSS score if not present
            if not hasattr(finding, 'cvss_score') or not finding.evidence.get('cvss_score'):
                cvss_score = self._calculate_cvss_score(finding)
                finding.evidence['cvss_score'] = cvss_score
            
            # Add exploit likelihood assessment
            exploit_likelihood = self._assess_exploit_likelihood(finding)
            finding.evidence['exploit_likelihood'] = exploit_likelihood
            
            # Add business impact assessment
            business_impact = self._assess_business_impact(finding)
            finding.evidence['business_impact'] = business_impact
            
            # Add remediation priority
            remediation_priority = self._calculate_remediation_priority(finding)
            finding.evidence['remediation_priority'] = remediation_priority
            
            # Update confidence based on correlation
            if finding.evidence.get('correlation_count', 0) > 1:
                finding.confidence = min(1.0, finding.confidence + 0.1)
            
            enriched.append(finding)
        
        return enriched
    
    def _initialize_correlation_rules(self) -> List[CorrelationRule]:
        """Initialize vulnerability correlation rules"""
        return [
            CorrelationRule(
                name="sql_injection_chain",
                vulnerability_types=["sql_injection", "blind_sqli"],
                url_similarity_threshold=0.9,
                parameter_similarity_threshold=0.8,
                evidence_correlation_func=self._correlate_sql_injection,
                severity_escalation_rule=lambda vulns: max(v.severity for v in vulns)
            ),
            
            CorrelationRule(
                name="xss_chain",
                vulnerability_types=["xss", "reflected_xss", "stored_xss"],
                url_similarity_threshold=0.9,
                parameter_similarity_threshold=0.7,
                evidence_correlation_func=self._correlate_xss,
                severity_escalation_rule=lambda vulns: VulnSeverity.HIGH if len(vulns) > 2 else max(v.severity for v in vulns)
            ),
            
            CorrelationRule(
                name="file_access_chain",
                vulnerability_types=["path_traversal", "file_inclusion", "file_upload"],
                url_similarity_threshold=0.8,
                parameter_similarity_threshold=0.6,
                evidence_correlation_func=self._correlate_file_access,
                severity_escalation_rule=lambda vulns: VulnSeverity.CRITICAL if len(vulns) > 1 else max(v.severity for v in vulns)
            ),
            
            CorrelationRule(
                name="injection_chain",
                vulnerability_types=["command_injection", "code_injection", "rce"],
                url_similarity_threshold=0.9,
                parameter_similarity_threshold=0.8,
                evidence_correlation_func=self._correlate_injection,
                severity_escalation_rule=lambda vulns: VulnSeverity.CRITICAL
            )
        ]
    
    def _initialize_false_positive_patterns(self) -> List[Dict[str, Any]]:
        """Initialize false positive detection patterns"""
        return [
            {
                "name": "generic_error_messages",
                "vulnerability_types": ["sql_injection"],
                "patterns": [r"error", r"exception", r"warning"],
                "exclusions": [r"mysql", r"postgresql", r"sql.*syntax"],
                "reason": "Generic error message without SQL-specific indicators",
                "confidence_threshold": 0.5
            },
            
            {
                "name": "reflected_input_without_execution",
                "vulnerability_types": ["xss"],
                "patterns": [r"<[^>]*>"],
                "exclusions": [r"<script", r"javascript:", r"on\w+\s*="],
                "reason": "Reflected input without executable context",
                "confidence_threshold": 0.6
            },
            
            {
                "name": "expected_file_contents",
                "vulnerability_types": ["path_traversal"],
                "patterns": [r"root:x:", r"daemon:x:"],
                "exclusions": [],
                "reason": "Expected file contents in legitimate context",
                "confidence_threshold": 0.4
            },
            
            {
                "name": "timeout_false_positive",
                "vulnerability_types": ["command_injection", "sql_injection"],
                "patterns": [],
                "exclusions": [],
                "reason": "Timeout-based detection with insufficient evidence",
                "confidence_threshold": 0.3
            }
        ]
    
    def _initialize_severity_rules(self) -> List[Dict[str, Any]]:
        """Initialize severity escalation rules"""
        return [
            {
                "name": "multiple_injection_points",
                "condition": lambda findings: len([f for f in findings if "injection" in f.name.lower()]) > 2,
                "escalation": lambda severity: VulnSeverity.CRITICAL if severity == VulnSeverity.HIGH else severity,
                "reason": "Multiple injection vulnerabilities increase overall risk"
            },
            
            {
                "name": "admin_panel_vulnerability",
                "condition": lambda findings: any("admin" in f.affected_url.lower() for f in findings),
                "escalation": lambda severity: VulnSeverity.CRITICAL if severity in [VulnSeverity.HIGH, VulnSeverity.MEDIUM] else severity,
                "reason": "Vulnerabilities in admin panels have higher impact"
            },
            
            {
                "name": "authentication_bypass",
                "condition": lambda findings: any(any(tag in ["auth", "login", "session"] for tag in f.tags) for f in findings),
                "escalation": lambda severity: VulnSeverity.CRITICAL,
                "reason": "Authentication-related vulnerabilities are critical"
            },
            
            {
                "name": "data_exposure_with_access",
                "condition": lambda findings: any("exposure" in f.name.lower() for f in findings) and any("injection" in f.name.lower() for f in findings),
                "escalation": lambda severity: VulnSeverity.CRITICAL,
                "reason": "Data exposure combined with injection allows full compromise"
            }
        ]
    
    def _matches_false_positive_pattern(self, finding: VulnerabilityFinding, pattern_info: Dict[str, Any]) -> bool:
        """Check if finding matches false positive pattern"""
        
        # Check vulnerability type
        if finding.name.lower() not in [vt.lower() for vt in pattern_info.get("vulnerability_types", [])]:
            return False
        
        # Check confidence threshold
        if finding.confidence > pattern_info.get("confidence_threshold", 1.0):
            return False
        
        # Check patterns in evidence
        evidence_text = str(finding.evidence).lower()
        response_text = finding.evidence.get("response", "").lower()
        combined_text = f"{evidence_text} {response_text}"
        
        # Must match at least one pattern
        patterns = pattern_info.get("patterns", [])
        if patterns:
            pattern_matches = any(re.search(pattern, combined_text, re.IGNORECASE) for pattern in patterns)
            if not pattern_matches:
                return False
        
        # Must not match exclusion patterns
        exclusions = pattern_info.get("exclusions", [])
        if exclusions:
            exclusion_matches = any(re.search(exclusion, combined_text, re.IGNORECASE) for exclusion in exclusions)
            if exclusion_matches:
                return False
        
        return True
    
    def _calculate_finding_similarity(self, finding1: VulnerabilityFinding, finding2: VulnerabilityFinding) -> float:
        """Calculate similarity score between two findings"""
        
        similarity_factors = []
        
        # Vulnerability name similarity
        name_similarity = difflib.SequenceMatcher(None, finding1.name.lower(), finding2.name.lower()).ratio()
        similarity_factors.append(("name", name_similarity, 0.3))
        
        # URL similarity
        url_similarity = difflib.SequenceMatcher(None, finding1.affected_url, finding2.affected_url).ratio()
        similarity_factors.append(("url", url_similarity, 0.4))
        
        # Parameter similarity
        param1 = finding1.affected_parameter or ""
        param2 = finding2.affected_parameter or ""
        param_similarity = difflib.SequenceMatcher(None, param1.lower(), param2.lower()).ratio()
        similarity_factors.append(("parameter", param_similarity, 0.2))
        
        # Payload similarity
        payload1 = finding1.payload or ""
        payload2 = finding2.payload or ""
        payload_similarity = difflib.SequenceMatcher(None, payload1.lower(), payload2.lower()).ratio()
        similarity_factors.append(("payload", payload_similarity, 0.1))
        
        # Calculate weighted similarity
        total_similarity = sum(similarity * weight for _, similarity, weight in similarity_factors)
        
        return total_similarity
    
    def _merge_similar_findings(self, findings: List[VulnerabilityFinding]) -> VulnerabilityFinding:
        """Merge similar findings into a single finding"""
        
        if len(findings) == 1:
            return findings[0]
        
        # Use the finding with highest confidence as base
        base_finding = max(findings, key=lambda f: f.confidence)
        
        # Merge evidence from all findings
        merged_evidence = base_finding.evidence.copy()
        merged_evidence["merged_from_count"] = len(findings)
        merged_evidence["correlation_count"] = len(findings)
        merged_evidence["merged_findings"] = []
        
        # Collect all scan engines and tools
        scan_engines = set()
        discovered_by_tools = set()
        
        for finding in findings:
            scan_engines.add(finding.scan_engine.value if hasattr(finding.scan_engine, 'value') else str(finding.scan_engine))
            discovered_by_tools.add(finding.discovered_by)
            
            merged_evidence["merged_findings"].append({
                "name": finding.name,
                "confidence": finding.confidence,
                "scan_engine": finding.scan_engine.value if hasattr(finding.scan_engine, 'value') else str(finding.scan_engine),
                "discovered_by": finding.discovered_by,
                "payload": finding.payload
            })
        
        # Update base finding
        base_finding.confidence = min(1.0, base_finding.confidence + (len(findings) - 1) * 0.1)
        base_finding.evidence = merged_evidence
        base_finding.discovered_by = f"multiple_scanners({', '.join(discovered_by_tools)})"
        
        # Add correlation tags
        base_finding.tags.extend(["correlated", "multi_scanner", f"confidence_{len(findings)}x"])
        
        return base_finding
    
    async def _apply_correlation_rule(self, findings: List[VulnerabilityFinding], rule: CorrelationRule) -> List[VulnerabilityFinding]:
        """Apply a specific correlation rule to findings"""
        
        # Filter findings that match the rule
        relevant_findings = [f for f in findings if any(vt in f.name.lower() for vt in rule.vulnerability_types)]
        
        if len(relevant_findings) < 2:
            return findings
        
        # Group by URL similarity
        correlation_groups = []
        processed = set()
        
        for i, finding in enumerate(relevant_findings):
            if i in processed:
                continue
            
            group = [finding]
            processed.add(i)
            
            for j, other_finding in enumerate(relevant_findings[i+1:], i+1):
                if j in processed:
                    continue
                
                url_similarity = difflib.SequenceMatcher(None, finding.affected_url, other_finding.affected_url).ratio()
                param_similarity = 1.0 if not finding.affected_parameter and not other_finding.affected_parameter else \
                    difflib.SequenceMatcher(None, finding.affected_parameter or "", other_finding.affected_parameter or "").ratio()
                
                if (url_similarity >= rule.url_similarity_threshold and 
                    param_similarity >= rule.parameter_similarity_threshold):
                    group.append(other_finding)
                    processed.add(j)
            
            if len(group) > 1:
                correlation_groups.append(group)
        
        # Apply correlation to groups
        updated_findings = findings.copy()
        
        for group in correlation_groups:
            # Apply correlation function
            if rule.evidence_correlation_func:
                correlated_evidence = rule.evidence_correlation_func(group)
                
                # Update findings with correlation evidence
                for finding in group:
                    finding.evidence.update(correlated_evidence)
                    finding.evidence["correlation_rule"] = rule.name
                    finding.evidence["correlated_with"] = [f.vulnerability_id for f in group if f != finding]
                    
                    # Apply severity escalation
                    if rule.severity_escalation_rule:
                        new_severity = rule.severity_escalation_rule(group)
                        if new_severity != finding.severity:
                            finding.severity = new_severity
                            finding.evidence["severity_escalated"] = True
                            finding.evidence["escalation_reason"] = rule.name
        
        return updated_findings
    
    def _apply_escalation_rules_to_group(self, findings: List[VulnerabilityFinding]) -> List[VulnerabilityFinding]:
        """Apply severity escalation rules to a group of findings"""
        
        for rule in self.severity_escalation_rules:
            if rule["condition"](findings):
                for finding in findings:
                    original_severity = finding.severity
                    new_severity = rule["escalation"](finding.severity)
                    
                    if new_severity != original_severity:
                        finding.severity = new_severity
                        finding.evidence["severity_escalated"] = True
                        finding.evidence["escalation_reason"] = rule["reason"]
                        finding.evidence["original_severity"] = original_severity.value
        
        return findings
    
    # Correlation functions
    
    def _correlate_sql_injection(self, findings: List[VulnerabilityFinding]) -> Dict[str, Any]:
        """Correlate SQL injection findings"""
        
        techniques = set()
        databases = set()
        
        for finding in findings:
            # Extract SQL injection techniques
            if "time" in finding.evidence.get("detection_method", "").lower():
                techniques.add("time_based")
            if "error" in finding.evidence.get("detection_method", "").lower():
                techniques.add("error_based")
            if "union" in finding.evidence.get("detection_method", "").lower():
                techniques.add("union_based")
            
            # Extract database types
            evidence_text = str(finding.evidence).lower()
            if "mysql" in evidence_text:
                databases.add("mysql")
            if "postgresql" in evidence_text:
                databases.add("postgresql")
            if "mssql" in evidence_text or "microsoft" in evidence_text:
                databases.add("mssql")
            if "oracle" in evidence_text:
                databases.add("oracle")
        
        return {
            "sql_injection_techniques": list(techniques),
            "detected_databases": list(databases),
            "correlation_type": "sql_injection_chain",
            "attack_complexity": "high" if len(techniques) > 2 else "medium"
        }
    
    def _correlate_xss(self, findings: List[VulnerabilityFinding]) -> Dict[str, Any]:
        """Correlate XSS findings"""
        
        contexts = set()
        payload_types = set()
        
        for finding in findings:
            # Extract XSS contexts
            context = finding.evidence.get("reflection_context", "")
            if context:
                contexts.add(context)
            
            # Extract payload types
            payload = finding.payload or ""
            if "script" in payload.lower():
                payload_types.add("script_injection")
            if "img" in payload.lower():
                payload_types.add("image_injection")
            if "javascript:" in payload.lower():
                payload_types.add("javascript_protocol")
        
        return {
            "xss_contexts": list(contexts),
            "payload_types": list(payload_types),
            "correlation_type": "xss_chain",
            "bypass_potential": "high" if len(payload_types) > 2 else "medium"
        }
    
    def _correlate_file_access(self, findings: List[VulnerabilityFinding]) -> Dict[str, Any]:
        """Correlate file access vulnerabilities"""
        
        access_methods = set()
        file_types = set()
        
        for finding in findings:
            vuln_name = finding.name.lower()
            
            if "traversal" in vuln_name:
                access_methods.add("path_traversal")
            if "inclusion" in vuln_name:
                access_methods.add("file_inclusion")
            if "upload" in vuln_name:
                access_methods.add("file_upload")
            
            # Extract accessed file types from evidence
            evidence_text = str(finding.evidence).lower()
            if "passwd" in evidence_text or "root:x:" in evidence_text:
                file_types.add("system_files")
            if "config" in evidence_text:
                file_types.add("configuration_files")
            if ".php" in evidence_text or ".jsp" in evidence_text:
                file_types.add("executable_files")
        
        return {
            "file_access_methods": list(access_methods),
            "accessed_file_types": list(file_types),
            "correlation_type": "file_access_chain",
            "compromise_potential": "critical" if "executable_files" in file_types else "high"
        }
    
    def _correlate_injection(self, findings: List[VulnerabilityFinding]) -> Dict[str, Any]:
        """Correlate injection vulnerabilities"""
        
        injection_types = set()
        execution_evidence = []
        
        for finding in findings:
            vuln_name = finding.name.lower()
            
            if "command" in vuln_name:
                injection_types.add("command_injection")
            if "code" in vuln_name:
                injection_types.add("code_injection")
            if "rce" in vuln_name:
                injection_types.add("remote_code_execution")
            
            # Extract execution evidence
            evidence = finding.evidence
            if evidence.get("command_output") or evidence.get("execution_confirmed"):
                execution_evidence.append(finding.vulnerability_id)
        
        return {
            "injection_types": list(injection_types),
            "execution_confirmed": len(execution_evidence) > 0,
            "confirmed_findings": execution_evidence,
            "correlation_type": "injection_chain",
            "system_compromise_risk": "critical"
        }
    
    # Utility methods
    
    def _get_base_url(self, url: str) -> str:
        """Get base URL from full URL"""
        from urllib.parse import urlparse
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    
    def _calculate_cvss_score(self, finding: VulnerabilityFinding) -> float:
        """Calculate CVSS score for finding"""
        
        # Base scores by severity
        base_scores = {
            VulnSeverity.CRITICAL: 9.0,
            VulnSeverity.HIGH: 7.0,
            VulnSeverity.MEDIUM: 5.0,
            VulnSeverity.LOW: 3.0,
            VulnSeverity.INFO: 0.0
        }
        
        base_score = base_scores.get(finding.severity, 5.0)
        
        # Adjust based on vulnerability characteristics
        if "injection" in finding.name.lower():
            base_score += 1.0  # Injection vulnerabilities are more severe
        
        if finding.evidence.get("execution_confirmed"):
            base_score += 1.5  # Confirmed exploitation increases severity
        
        if finding.confidence > 0.9:
            base_score += 0.5  # High confidence findings
        
        # Correlation boost
        if finding.evidence.get("correlation_count", 0) > 1:
            base_score += 0.3 * (finding.evidence["correlation_count"] - 1)
        
        return min(10.0, max(0.0, base_score))
    
    def _assess_exploit_likelihood(self, finding: VulnerabilityFinding) -> str:
        """Assess likelihood of successful exploitation"""
        
        likelihood_factors = []
        
        # Base likelihood by vulnerability type
        vuln_name = finding.name.lower()
        if any(term in vuln_name for term in ["injection", "rce", "upload"]):
            likelihood_factors.append(("vulnerability_type", 0.8))
        elif any(term in vuln_name for term in ["xss", "csrf", "exposure"]):
            likelihood_factors.append(("vulnerability_type", 0.6))
        else:
            likelihood_factors.append(("vulnerability_type", 0.4))
        
        # Confidence factor
        likelihood_factors.append(("confidence", finding.confidence))
        
        # Evidence quality
        if finding.evidence.get("execution_confirmed"):
            likelihood_factors.append(("execution_confirmed", 0.9))
        elif finding.evidence.get("payload_reflected"):
            likelihood_factors.append(("payload_reflected", 0.7))
        
        # Correlation factor
        correlation_count = finding.evidence.get("correlation_count", 1)
        if correlation_count > 1:
            likelihood_factors.append(("correlation", min(0.9, 0.5 + (correlation_count - 1) * 0.1)))
        
        # Calculate weighted likelihood
        total_weight = sum(weight for _, weight in likelihood_factors)
        weighted_likelihood = total_weight / len(likelihood_factors) if likelihood_factors else 0.5
        
        if weighted_likelihood >= 0.8:
            return "very_high"
        elif weighted_likelihood >= 0.6:
            return "high"
        elif weighted_likelihood >= 0.4:
            return "medium"
        elif weighted_likelihood >= 0.2:
            return "low"
        else:
            return "very_low"
    
    def _assess_business_impact(self, finding: VulnerabilityFinding) -> str:
        """Assess business impact of vulnerability"""
        
        impact_indicators = []
        
        # URL-based impact assessment
        url = finding.affected_url.lower()
        if any(term in url for term in ["admin", "management", "control"]):
            impact_indicators.append("admin_access")
        if any(term in url for term in ["api", "service", "endpoint"]):
            impact_indicators.append("api_exposure")
        if any(term in url for term in ["login", "auth", "signin"]):
            impact_indicators.append("authentication_impact")
        if any(term in url for term in ["payment", "billing", "checkout"]):
            impact_indicators.append("financial_impact")
        
        # Vulnerability-based impact
        vuln_name = finding.name.lower()
        if any(term in vuln_name for term in ["injection", "rce", "upload"]):
            impact_indicators.append("system_compromise")
        if any(term in vuln_name for term in ["exposure", "disclosure", "leak"]):
            impact_indicators.append("data_exposure")
        if any(term in vuln_name for term in ["auth", "session", "login"]):
            impact_indicators.append("access_control")
        
        # Severity consideration
        if finding.severity == VulnSeverity.CRITICAL:
            impact_indicators.append("critical_severity")
        
        # Determine overall impact
        critical_indicators = {"admin_access", "financial_impact", "system_compromise", "critical_severity"}
        high_indicators = {"api_exposure", "authentication_impact", "data_exposure", "access_control"}
        
        if any(indicator in critical_indicators for indicator in impact_indicators):
            return "critical"
        elif any(indicator in high_indicators for indicator in impact_indicators):
            return "high"
        elif impact_indicators:
            return "medium"
        else:
            return "low"
    
    def _calculate_remediation_priority(self, finding: VulnerabilityFinding) -> int:
        """Calculate remediation priority (1-10, 10 being highest)"""
        
        priority = 5  # Base priority
        
        # Severity adjustment
        severity_adjustments = {
            VulnSeverity.CRITICAL: 4,
            VulnSeverity.HIGH: 3,
            VulnSeverity.MEDIUM: 1,
            VulnSeverity.LOW: -1,
            VulnSeverity.INFO: -2
        }
        priority += severity_adjustments.get(finding.severity, 0)
        
        # Exploit likelihood adjustment
        exploit_likelihood = finding.evidence.get("exploit_likelihood", "medium")
        likelihood_adjustments = {
            "very_high": 2,
            "high": 1,
            "medium": 0,
            "low": -1,
            "very_low": -2
        }
        priority += likelihood_adjustments.get(exploit_likelihood, 0)
        
        # Business impact adjustment
        business_impact = finding.evidence.get("business_impact", "medium")
        impact_adjustments = {
            "critical": 2,
            "high": 1,
            "medium": 0,
            "low": -1
        }
        priority += impact_adjustments.get(business_impact, 0)
        
        # Correlation adjustment
        if finding.evidence.get("correlation_count", 0) > 1:
            priority += 1
        
        return max(1, min(10, priority))
    
    def get_analysis_statistics(self, original_count: int, final_count: int) -> Dict[str, Any]:
        """Get analysis statistics"""
        return {
            "original_findings": original_count,
            "final_findings": final_count,
            "reduction_percentage": ((original_count - final_count) / original_count * 100) if original_count > 0 else 0,
            "false_positives_filtered": original_count - final_count,
            "correlation_rules_applied": len(self.correlation_rules),
            "escalation_rules_applied": len(self.severity_escalation_rules)
        }
        