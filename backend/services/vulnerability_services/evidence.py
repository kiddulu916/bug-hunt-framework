"""
Evidence handling service for vulnerability management.
Manages file uploads, evidence validation, and evidence organization.
"""

import os
import uuid
import hashlib
import logging
import mimetypes
import magic
from typing import List, Dict, Optional, Any, BinaryIO
from datetime import datetime
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import json

from fastapi import UploadFile
from core.constants import (
    ALLOWED_EVIDENCE_EXTENSIONS, 
    MAX_UPLOAD_SIZE_BYTES,
    BUG_BOUNTY_PLATFORMS
)
from core.exceptions import (
    FileUploadException,
    FileProcessingException,
    InvalidFileFormatException
)

logger = logging.getLogger(__name__)

class EvidenceHandler:
    """
    Service for handling vulnerability evidence files.
    Manages uploads, validation, processing, and organization of evidence.
    """
    
    def __init__(self):
        self.evidence_dir = Path(BUG_BOUNTY_PLATFORMS.get('EVIDENCE_STORAGE_DIR', './evidence'))
        self.max_file_size = BUG_BOUNTY_PLATFORMS.get('MAX_UPLOAD_SIZE', 10485760)  # 10MB default
        
        # Ensure evidence directory exists
        self.evidence_dir.mkdir(parents=True, exist_ok=True)
        
        # Supported file types for evidence
        self.image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']
        self.document_extensions = ['.pdf', '.txt', '.md', '.html', '.json', '.xml']
        self.archive_extensions = ['.zip', '.tar', '.gz']
        
        # Evidence categories
        self.evidence_categories = {
            'screenshot': ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'],
            'request_response': ['txt', 'json', 'html', 'xml'],
            'payload': ['txt', 'json'],
            'tool_output': ['txt', 'json', 'xml', 'html'],
            'documentation': ['pdf', 'md', 'txt'],
            'archive': ['zip', 'tar', 'gz']
        }

    async def save_evidence_file(self, file: UploadFile, vulnerability_id: str, 
                               category: str = 'screenshot') -> str:
        """
        Save uploaded evidence file for a vulnerability.
        
        Args:
            file: Uploaded file object
            vulnerability_id: Associated vulnerability ID
            category: Evidence category (screenshot, request_response, etc.)
            
        Returns:
            str: File path of saved evidence
            
        Raises:
            FileUploadException: If file upload fails
            InvalidFileFormatException: If file format is not supported
        """
        try:
            # Validate file
            await self._validate_uploaded_file(file)
            
            # Generate unique filename
            file_extension = self._get_file_extension(file.filename)
            unique_filename = self._generate_evidence_filename(
                vulnerability_id, category, file_extension
            )
            
            # Create directory structure
            evidence_path = self._create_evidence_directory(vulnerability_id)
            file_path = evidence_path / unique_filename
            
            # Save file
            await self._save_file_to_disk(file, file_path)
            
            # Process file based on type
            processed_info = await self._process_evidence_file(file_path, category)
            
            # Generate metadata
            metadata = await self._generate_file_metadata(file, file_path, processed_info)
            await self._save_metadata(file_path, metadata)
            
            logger.info(f"Evidence file saved: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"Error saving evidence file: {e}")
            if isinstance(e, (FileUploadException, InvalidFileFormatException)):
                raise
            raise FileUploadException(file.filename or "unknown", str(e))

    async def process_screenshot(self, file_path: str, vulnerability_id: str) -> Dict[str, Any]:
        """
        Process screenshot evidence with annotations and metadata extraction.
        
        Args:
            file_path: Path to screenshot file
            vulnerability_id: Associated vulnerability ID
            
        Returns:
            dict: Processing results and metadata
        """
        try:
            image_path = Path(file_path)
            
            if not image_path.exists():
                raise FileProcessingException(str(image_path), "processing", "File not found")
            
            # Load image
            with Image.open(image_path) as img:
                # Extract image metadata
                metadata = {
                    'format': img.format,
                    'mode': img.mode,
                    'size': img.size,
                    'has_transparency': img.mode in ('RGBA', 'LA') or 'transparency' in img.info
                }
                
                # Create annotated version
                annotated_path = await self._create_annotated_screenshot(
                    img, image_path, vulnerability_id
                )
                
                # Generate thumbnail
                thumbnail_path = await self._create_thumbnail(img, image_path)
                
                return {
                    'original_path': str(image_path),
                    'annotated_path': annotated_path,
                    'thumbnail_path': thumbnail_path,
                    'metadata': metadata,
                    'processed_at': datetime.utcnow()
                }
                
        except Exception as e:
            logger.error(f"Error processing screenshot {file_path}: {e}")
            raise FileProcessingException(file_path, "screenshot_processing", str(e))

    async def extract_request_response_data(self, file_path: str) -> Dict[str, Any]:
        """
        Extract and parse HTTP request/response data from evidence files.
        
        Args:
            file_path: Path to request/response file
            
        Returns:
            dict: Parsed request/response data
        """
        try:
            file_path_obj = Path(file_path)
            
            if not file_path_obj.exists():
                raise FileProcessingException(file_path, "extraction", "File not found")
            
            # Read file content
            with open(file_path_obj, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Parse based on file extension
            extension = file_path_obj.suffix.lower()
            
            if extension == '.json':
                return await self._parse_json_request_response(content)
            elif extension in ['.txt', '.html']:
                return await self._parse_text_request_response(content)
            elif extension == '.xml':
                return await self._parse_xml_request_response(content)
            else:
                return {'raw_content': content, 'parsed': False}
                
        except Exception as e:
            logger.error(f"Error extracting request/response data from {file_path}: {e}")
            raise FileProcessingException(file_path, "data_extraction", str(e))

    async def organize_evidence_by_type(self, vulnerability_id: str) -> Dict[str, List[str]]:
        """
        Organize evidence files by type for a vulnerability.
        
        Args:
            vulnerability_id: Vulnerability ID
            
        Returns:
            dict: Evidence files organized by category
        """
        try:
            evidence_path = self._create_evidence_directory(vulnerability_id)
            
            if not evidence_path.exists():
                return {}
            
            organized_evidence = {category: [] for category in self.evidence_categories.keys()}
            
            for file_path in evidence_path.iterdir():
                if file_path.is_file() and not file_path.name.startswith('.'):
                    category = self._determine_file_category(file_path)
                    if category:
                        organized_evidence[category].append(str(file_path))
            
            return organized_evidence
            
        except Exception as e:
            logger.error(f"Error organizing evidence for {vulnerability_id}: {e}")
            return {}

    async def generate_evidence_report(self, vulnerability_id: str) -> Dict[str, Any]:
        """
        Generate comprehensive evidence report for a vulnerability.
        
        Args:
            vulnerability_id: Vulnerability ID
            
        Returns:
            dict: Evidence report with analysis
        """
        try:
            organized_evidence = await self.organize_evidence_by_type(vulnerability_id)
            
            report = {
                'vulnerability_id': vulnerability_id,
                'generated_at': datetime.utcnow(),
                'evidence_summary': {},
                'file_analysis': {},
                'recommendations': []
            }
            
            total_files = 0
            total_size = 0
            
            for category, files in organized_evidence.items():
                if files:
                    category_info = {
                        'count': len(files),
                        'files': [],
                        'total_size': 0
                    }
                    
                    for file_path in files:
                        file_info = await self._analyze_evidence_file(file_path)
                        category_info['files'].append(file_info)
                        category_info['total_size'] += file_info.get('size', 0)
                    
                    report['evidence_summary'][category] = category_info
                    total_files += len(files)
                    total_size += category_info['total_size']
            
            report['totals'] = {
                'total_files': total_files,
                'total_size': total_size,
                'categories_with_evidence': len([c for c, f in organized_evidence.items() if f])
            }
            
            # Generate recommendations
            report['recommendations'] = self._generate_evidence_recommendations(organized_evidence)
            
            return report
            
        except Exception as e:
            logger.error(f"Error generating evidence report for {vulnerability_id}: {e}")
            raise FileProcessingException(vulnerability_id, "report_generation", str(e))

    async def cleanup_evidence(self, vulnerability_id: str, older_than_days: int = 90) -> Dict[str, Any]:
        """
        Clean up old evidence files for a vulnerability.
        
        Args:
            vulnerability_id: Vulnerability ID
            older_than_days: Remove files older than this many days
            
        Returns:
            dict: Cleanup results
        """
        try:
            evidence_path = self._create_evidence_directory(vulnerability_id)
            
            if not evidence_path.exists():
                return {'cleaned_files': 0, 'space_freed': 0}
            
            cutoff_time = datetime.utcnow().timestamp() - (older_than_days * 24 * 3600)
            cleaned_files = 0
            space_freed = 0
            
            for file_path in evidence_path.iterdir():
                if file_path.is_file():
                    file_mtime = file_path.stat().st_mtime
                    if file_mtime < cutoff_time:
                        file_size = file_path.stat().st_size
                        file_path.unlink()
                        cleaned_files += 1
                        space_freed += file_size
            
            return {
                'cleaned_files': cleaned_files,
                'space_freed': space_freed,
                'cleanup_date': datetime.utcnow()
            }
            
        except Exception as e:
            logger.error(f"Error cleaning up evidence for {vulnerability_id}: {e}")
            raise FileProcessingException(vulnerability_id, "cleanup", str(e))

    # Private helper methods

    async def _validate_uploaded_file(self, file: UploadFile) -> None:
        """Validate uploaded file for security and format compliance."""
        if not file.filename:
            raise FileUploadException("unknown", "No filename provided")
        
        # Check file size
        file.file.seek(0, 2)  # Seek to end
        file_size = file.file.tell()
        file.file.seek(0)  # Reset to beginning
        
        if file_size > self.max_file_size:
            raise FileUploadException(
                file.filename, 
                f"File size {file_size} exceeds maximum {self.max_file_size}"
            )
        
        if file_size == 0:
            raise FileUploadException(file.filename, "File is empty")
        
        # Check file extension
        extension = self._get_file_extension(file.filename)
        if extension not in ALLOWED_EVIDENCE_EXTENSIONS:
            raise InvalidFileFormatException(
                file.filename, 
                ALLOWED_EVIDENCE_EXTENSIONS
            )
        
        # Validate MIME type
        content = await file.read(1024)  # Read first 1KB for MIME detection
        await file.seek(0)  # Reset file pointer
        
        try:
            detected_mime = magic.from_buffer(content, mime=True)
            expected_mimes = self._get_expected_mime_types(extension)
            
            if detected_mime not in expected_mimes:
                logger.warning(f"MIME type mismatch for {file.filename}: detected {detected_mime}")
                # Don't fail on MIME mismatch, just log warning
        except Exception as e:
            logger.warning(f"Could not detect MIME type for {file.filename}: {e}")

    def _get_file_extension(self, filename: str) -> str:
        """Extract and validate file extension."""
        if not filename:
            return ""
        
        extension = Path(filename).suffix.lower()
        return extension

    def _get_expected_mime_types(self, extension: str) -> List[str]:
        """Get expected MIME types for file extension."""
        mime_mappings = {
            '.jpg': ['image/jpeg'],
            '.jpeg': ['image/jpeg'],
            '.png': ['image/png'],
            '.gif': ['image/gif'],
            '.bmp': ['image/bmp'],
            '.webp': ['image/webp'],
            '.pdf': ['application/pdf'],
            '.txt': ['text/plain'],
            '.json': ['application/json', 'text/plain'],
            '.html': ['text/html'],
            '.xml': ['application/xml', 'text/xml'],
            '.zip': ['application/zip'],
            '.tar': ['application/x-tar'],
            '.gz': ['application/gzip']
        }
        
        return mime_mappings.get(extension, ['application/octet-stream'])

    def _generate_evidence_filename(self, vulnerability_id: str, category: str, extension: str) -> str:
        """Generate unique filename for evidence."""
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        
        return f"{category}_{timestamp}_{unique_id}{extension}"

    def _create_evidence_directory(self, vulnerability_id: str) -> Path:
        """Create and return evidence directory for vulnerability."""
        vuln_dir = self.evidence_dir / vulnerability_id
        vuln_dir.mkdir(parents=True, exist_ok=True)
        return vuln_dir

    async def _save_file_to_disk(self, file: UploadFile, file_path: Path) -> None:
        """Save uploaded file to disk."""
        try:
            with open(file_path, 'wb') as f:
                content = await file.read()
                f.write(content)
        except Exception as e:
            if file_path.exists():
                file_path.unlink()  # Clean up partial file
            raise FileUploadException(file.filename or "unknown", f"Failed to save file: {e}")

    async def _process_evidence_file(self, file_path: Path, category: str) -> Dict[str, Any]:
        """Process evidence file based on category and type."""
        processing_info = {
            'category': category,
            'processed_at': datetime.utcnow(),
            'processing_steps': []
        }
        
        extension = file_path.suffix.lower()
        
        try:
            if extension in self.image_extensions:
                # Process image file
                image_info = await self._process_image_file(file_path)
                processing_info.update(image_info)
                processing_info['processing_steps'].append('image_processing')
            
            elif extension in ['.txt', '.json', '.html', '.xml']:
                # Process text/data file
                text_info = await self._process_text_file(file_path)
                processing_info.update(text_info)
                processing_info['processing_steps'].append('text_processing')
            
            elif extension == '.pdf':
                # Process PDF file
                pdf_info = await self._process_pdf_file(file_path)
                processing_info.update(pdf_info)
                processing_info['processing_steps'].append('pdf_processing')
            
            return processing_info
            
        except Exception as e:
            logger.error(f"Error processing evidence file {file_path}: {e}")
            processing_info['processing_error'] = str(e)
            return processing_info

    async def _process_image_file(self, file_path: Path) -> Dict[str, Any]:
        """Process image evidence file."""
        try:
            with Image.open(file_path) as img:
                return {
                    'image_format': img.format,
                    'image_mode': img.mode,
                    'image_size': img.size,
                    'has_exif': bool(img._getexif()) if hasattr(img, '_getexif') else False,
                    'file_size': file_path.stat().st_size
                }
        except Exception as e:
            return {'processing_error': f"Image processing failed: {e}"}

    async def _process_text_file(self, file_path: Path) -> Dict[str, Any]:
        """Process text-based evidence file."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            return {
                'content_length': len(content),
                'line_count': content.count('\n') + 1,
                'character_encoding': 'utf-8',
                'file_size': file_path.stat().st_size,
                'contains_http_headers': 'HTTP/' in content or 'Content-Type:' in content
            }
        except Exception as e:
            return {'processing_error': f"Text processing failed: {e}"}

    async def _process_pdf_file(self, file_path: Path) -> Dict[str, Any]:
        """Process PDF evidence file."""
        try:
            # Basic PDF information without heavy dependencies
            return {
                'file_size': file_path.stat().st_size,
                'file_type': 'pdf',
                'requires_pdf_reader': True
            }
        except Exception as e:
            return {'processing_error': f"PDF processing failed: {e}"}

    async def _generate_file_metadata(self, file: UploadFile, file_path: Path, 
                                    processing_info: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive metadata for evidence file."""
        stat_info = file_path.stat()
        
        metadata = {
            'original_filename': file.filename,
            'saved_filename': file_path.name,
            'file_path': str(file_path),
            'content_type': file.content_type,
            'file_size': stat_info.st_size,
            'created_at': datetime.fromtimestamp(stat_info.st_ctime),
            'modified_at': datetime.fromtimestamp(stat_info.st_mtime),
            'file_hash': await self._calculate_file_hash(file_path),
            'processing_info': processing_info
        }
        
        return metadata

    async def _save_metadata(self, file_path: Path, metadata: Dict[str, Any]) -> None:
        """Save metadata to accompanying JSON file."""
        metadata_path = file_path.with_suffix(file_path.suffix + '.meta.json')
        
        try:
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2, default=str)
        except Exception as e:
            logger.warning(f"Could not save metadata for {file_path}: {e}")

    async def _calculate_file_hash(self, file_path: Path) -> str:
        """Calculate SHA-256 hash of file."""
        hash_sha256 = hashlib.sha256()
        
        try:
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            logger.warning(f"Could not calculate hash for {file_path}: {e}")
            return ""

    async def _create_annotated_screenshot(self, img: Image.Image, original_path: Path, 
                                         vulnerability_id: str) -> str:
        """Create annotated version of screenshot with vulnerability details."""
        try:
            # Create a copy for annotation
            annotated = img.copy()
            draw = ImageDraw.Draw(annotated)
            
            # Add annotation box
            box_height = 60
            box_width = min(img.width, 400)
            
            # Draw background rectangle
            draw.rectangle([10, 10, box_width + 10, box_height + 10], fill='red', outline='darkred', width=2)
            
            # Add text (using default font if available)
            try:
                font = ImageFont.load_default()
            except:
                font = None
            
            text_lines = [
                f"Vulnerability ID: {vulnerability_id[:16]}...",
                f"Evidence captured: {datetime.utcnow().strftime('%Y-%m-%d %H:%M')}"
            ]
            
            y_offset = 15
            for line in text_lines:
                draw.text((15, y_offset), line, fill='white', font=font)
                y_offset += 20
            
            # Save annotated version
            annotated_path = original_path.with_stem(original_path.stem + '_annotated')
            annotated.save(annotated_path, quality=90)
            
            return str(annotated_path)
            
        except Exception as e:
            logger.warning(f"Could not create annotated screenshot: {e}")
            return str(original_path)

    async def _create_thumbnail(self, img: Image.Image, original_path: Path) -> str:
        """Create thumbnail version of image."""
        try:
            thumbnail = img.copy()
            thumbnail.thumbnail((200, 200), Image.Resampling.LANCZOS)
            
            thumbnail_path = original_path.with_stem(original_path.stem + '_thumb')
            thumbnail.save(thumbnail_path, quality=75)
            
            return str(thumbnail_path)
            
        except Exception as e:
            logger.warning(f"Could not create thumbnail: {e}")
            return str(original_path)

    def _determine_file_category(self, file_path: Path) -> Optional[str]:
        """Determine evidence category based on file characteristics."""
        extension = file_path.suffix.lower().lstrip('.')
        
        for category, extensions in self.evidence_categories.items():
            if extension in extensions:
                return category
        
        return None

    async def _parse_json_request_response(self, content: str) -> Dict[str, Any]:
        """Parse JSON request/response data."""
        try:
            data = json.loads(content)
            return {
                'format': 'json',
                'parsed': True,
                'request': data.get('request', {}),
                'response': data.get('response', {}),
                'metadata': data.get('metadata', {})
            }
        except json.JSONDecodeError as e:
            return {
                'format': 'json',
                'parsed': False,
                'error': f"JSON parsing error: {e}",
                'raw_content': content[:1000]  # First 1000 chars
            }

    async def _parse_text_request_response(self, content: str) -> Dict[str, Any]:
        """Parse text-based request/response data."""
        lines = content.split('\n')
        
        # Look for HTTP request/response patterns
        request_start = None
        response_start = None
        
        for i, line in enumerate(lines):
            if line.startswith(('GET ', 'POST ', 'PUT ', 'DELETE ', 'PATCH ', 'HEAD ', 'OPTIONS ')):
                request_start = i
            elif line.startswith('HTTP/'):
                response_start = i
        
        parsed_data = {
            'format': 'text',
            'parsed': True,
            'total_lines': len(lines)
        }
        
        if request_start is not None:
            parsed_data['has_request'] = True
            parsed_data['request_line'] = lines[request_start]
        
        if response_start is not None:
            parsed_data['has_response'] = True
            parsed_data['response_line'] = lines[response_start]
        
        return parsed_data

    async def _parse_xml_request_response(self, content: str) -> Dict[str, Any]:
        """Parse XML request/response data."""
        try:
            import xml.etree.ElementTree as ET
            root = ET.fromstring(content)
            
            return {
                'format': 'xml',
                'parsed': True,
                'root_element': root.tag,
                'element_count': len(list(root.iter()))
            }
        except ET.ParseError as e:
            return {
                'format': 'xml',
                'parsed': False,
                'error': f"XML parsing error: {e}",
                'raw_content': content[:1000]
            }

    async def _analyze_evidence_file(self, file_path: str) -> Dict[str, Any]:
        """Analyze individual evidence file for reporting."""
        file_path_obj = Path(file_path)
        
        if not file_path_obj.exists():
            return {'error': 'File not found'}
        
        stat_info = file_path_obj.stat()
        
        analysis = {
            'filename': file_path_obj.name,
            'path': str(file_path_obj),
            'size': stat_info.st_size,
            'created': datetime.fromtimestamp(stat_info.st_ctime),
            'modified': datetime.fromtimestamp(stat_info.st_mtime),
            'extension': file_path_obj.suffix.lower(),
            'category': self._determine_file_category(file_path_obj)
        }
        
        # Load metadata if available
        metadata_path = file_path_obj.with_suffix(file_path_obj.suffix + '.meta.json')
        if metadata_path.exists():
            try:
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                analysis['metadata'] = metadata
            except Exception as e:
                analysis['metadata_error'] = str(e)
        
        return analysis

    def _generate_evidence_recommendations(self, organized_evidence: Dict[str, List[str]]) -> List[str]:
        """Generate recommendations based on evidence analysis."""
        recommendations = []
        
        # Check for missing evidence types
        if not organized_evidence.get('screenshot'):
            recommendations.append("Consider adding screenshots to provide visual proof of vulnerability")
        
        if not organized_evidence.get('request_response'):
            recommendations.append("Include HTTP request/response data to show technical details")
        
        if not organized_evidence.get('payload'):
            recommendations.append("Document the specific payload used to exploit the vulnerability")
        
        # Check for evidence quality
        total_files = sum(len(files) for files in organized_evidence.values())
        if total_files < 2:
            recommendations.append("Additional evidence would strengthen the vulnerability report")
        
        if organized_evidence.get('tool_output'):
            recommendations.append("Tool outputs provide good technical validation")
        
        return recommendations